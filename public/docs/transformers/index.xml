<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transformers on Deep Learning</title>
    <link>http://localhost:1313/docs/transformers/</link>
    <description>Recent content in Transformers on Deep Learning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/docs/transformers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transformers101</title>
      <link>http://localhost:1313/docs/transformers/transformers101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/transformers101/</guid>
      <description>&lt;h1 id=&#34;transformers-101&#34;&gt;&#xA;  Transformers 101&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#transformers-101&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;A transformer has 3 main components.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Multi-head scaled self-attention.&lt;/li&gt;&#xA;&lt;li&gt;MLP with residual connections and layer normalization.&lt;/li&gt;&#xA;&lt;li&gt;Positional encodings.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;tldr&#34;&gt;&#xA;  TLDR&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tldr&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Transformer&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \(\mathbf{X}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;embedding matrix&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{X} = \mathbf{X} + \mathbf{R}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;position encoding matrix&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{TransformerLayer}[\mathbf{X}]\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;transformer&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{SoftMax}[\mathbf{X}\mathbf{X}^{T}] \mathbf{X}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;dot-product self-attention&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{SoftMax}[\mathbf{X} \mathbf{W}^{q}\mathbf{W}^{kT}\mathbf{X}^{T}] \mathbf{X} \mathbf{W}^{v}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Query, Key, Value matrices&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{SoftMax}[\mathbf{Q}\mathbf{K}^{T}] \mathbf{V} \)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Query, Key, Value matrices&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{SoftMax}[\frac{\mathbf{Q}\mathbf{K}^{T}}{\sqrt{D}}] \mathbf{V} \)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Scaled dot-product self attention&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Y} = \text{Concat}[\mathbf{H}_1,...,\mathbf{H}_H]\mathbf{W}^o \)&#xA;&lt;/span&gt;&#xA; where &lt;span&gt;&#xA;  \(\mathbf{H}_h = \text{SoftMax}\left[\frac{\mathbf{Q_h}\mathbf{K_h}^{T}}{\sqrt{D_k}}\right] \mathbf{V_h}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Multi-head attention&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{Z} = \text{LayerNorm}\left[\mathbf{Y}(\mathbf{X})+\mathbf{X}\right]\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;layer normalization and residual connection&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{X^*} = \text{LayerNorm}\left[\text{MLP}(\mathbf{Z})+\mathbf{Z}\right]\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;MLP layer&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Parameter&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Count&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{E}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(VD\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The token embedding matrix. &lt;span&gt;&#xA;  \(V\)&#xA;&lt;/span&gt;&#xA; is the size of the vocabulary and &lt;span&gt;&#xA;  \(D\)&#xA;&lt;/span&gt;&#xA; is the dimensions of the embeddings.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{W}^q_h\)&#xA;&lt;/span&gt;&#xA; &lt;span&gt;&#xA;  \(\mathbf{W}^k_h\)&#xA;&lt;/span&gt;&#xA; &lt;span&gt;&#xA;  \(\mathbf{W}^v_h\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(3HD^2\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The query, key and the value matrices each of dimension &lt;span&gt;&#xA;  \(D \times D \)&#xA;&lt;/span&gt;&#xA;for the &lt;span&gt;&#xA;  \(H\)&#xA;&lt;/span&gt;&#xA;heads.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{W}^o\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(HD^2\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The output matrix of dimension &lt;span&gt;&#xA;  \(HD \times D \)&#xA;&lt;/span&gt;&#xA;.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(\mathbf{W}^{ff}_{1}\)&#xA;&lt;/span&gt;&#xA; &lt;span&gt;&#xA;  \(\mathbf{W}^{ff}_{2}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(2DD_{ff}\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;The parameters of the two-layer MLP.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;span&gt;&#xA;  \(8D^2\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Typically &lt;span&gt;&#xA;  \(D_{ff} = 4 D\)&#xA;&lt;/span&gt;&#xA;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;&lt;span&gt;&#xA;  \((4H+8)D^2\)&#xA;&lt;/span&gt;&#xA; total parameters&lt;/strong&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;multi-head-scaled-self-attention&#34;&gt;&#xA;  Multi-head scaled self-attention.&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#multi-head-scaled-self-attention&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;tokens&#34;&gt;&#xA;  Tokens&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tokens&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;We will start with the concept of &lt;strong&gt;tokens&lt;/strong&gt;. As token can be&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers102</title>
      <link>http://localhost:1313/docs/transformers/transformers102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/transformers102/</guid>
      <description>&lt;h2 id=&#34;transformer-language-models&#34;&gt;&#xA;  Transformer Language Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#transformer-language-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;category&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;task&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;example&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;sample use case&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;vec2seq&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;GPT&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;chat, image captioning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Encoder&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;seq2vec&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;BERT&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;sentiment analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;strong&gt;Encoder-Decoder&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;seq2seq&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;T5&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;machine translation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;auto-regressive-models&#34;&gt;&#xA;  Auto-regressive models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#auto-regressive-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Decompose the distribution over sequence of tokens into a product of conditional distributions.&lt;/p&gt;&#xA;&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \[p(x_1,...,x_N)=\prod_{n=1}^{N} p(x_n|x_1,...,x_{n-1})\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;h3 id=&#34;markov-models&#34;&gt;&#xA;  Markov models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#markov-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Assume the conditional distribution is independent of all previous tokens except the &lt;span&gt;&#xA;  \(L\)&#xA;&lt;/span&gt;&#xA; most recent tokens (known as &lt;span&gt;&#xA;  \(n\)&#xA;&lt;/span&gt;&#xA;-gram models).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Alignment</title>
      <link>http://localhost:1313/docs/transformers/alignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/alignment/</guid>
      <description>&lt;h1 id=&#34;alignment&#34;&gt;&#xA;  Alignment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#alignment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;LLMs are typically trained for next-token prediction.&lt;/p&gt;&#xA;&lt;p&gt;Pre-trained LLMs may not be able to follow user instructions because they were not trained to do so.&lt;/p&gt;&#xA;&lt;p&gt;Pre-trained LLMs may generate harmful content or perpetuate  biases inherent in their training data.&lt;/p&gt;&#xA;&#xA;&#xA;&lt;script src=&#34;http://localhost:1313/mermaid.min.js&#34;&gt;&lt;/script&gt;&#xA;&#xA;  &lt;script&gt;mermaid.initialize({&#xA;  &#34;flowchart&#34;: {&#xA;    &#34;useMaxWidth&#34;:true&#xA;  },&#xA;  &#34;theme&#34;: &#34;default&#34;&#xA;}&#xA;)&lt;/script&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;pre class=&#34;mermaid&#34;&gt;&#xA;---&#xA;title: LLM training stages&#xA;---&#xA;flowchart LR&#xA;    subgraph Pre-training&#xA;    A[Pre-training]&#xA;    end&#xA;    subgraph Post-training&#xA;    B[&#34;Instruction Alignment (SFT)&#34;]&#xA;    C[&#34;Preference Alignment (RLHF)&#34;]&#xA;    end&#xA;    subgraph Inference&#xA;    D[Prompt engineering]&#xA;    end&#xA;    A--&gt;B&#xA;    B--&gt;C&#xA;    C--&gt;D&#xA;&lt;/pre&gt;&#xA;&#xA;&lt;h2 id=&#34;fine-tune-llms-with-labelled-data&#34;&gt;&#xA;  Fine tune LLMs with labelled data&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#fine-tune-llms-with-labelled-data&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.11206&#34;&gt;https://arxiv.org/pdf/2305.11206&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Attention variants</title>
      <link>http://localhost:1313/docs/transformers/attentionvariants/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/attentionvariants/</guid>
      <description>&lt;h2 id=&#34;sliding-window&#34;&gt;&#xA;  Sliding window&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#sliding-window&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;linear-attention&#34;&gt;&#xA;  Linear attention&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#linear-attention&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.16236&#34;&gt;https://arxiv.org/abs/2006.16236&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;lower-dimensional-attention&#34;&gt;&#xA;  Lower-dimensional attention&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#lower-dimensional-attention&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;group-query-attention-gqa&#34;&gt;&#xA;  Group-Query Attention (GQA)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#group-query-attention-gqa&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.13245&#34;&gt;https://arxiv.org/pdf/2305.13245&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;multi-head-latent-attention-mla&#34;&gt;&#xA;  Multi-head Latent Attention (MLA)&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#multi-head-latent-attention-mla&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2405.04434&#34;&gt;https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inference</title>
      <link>http://localhost:1313/docs/transformers/inference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/inference/</guid>
      <description>&lt;p&gt;Prefill and decode.&lt;/p&gt;&#xA;&lt;p&gt;Prefill (similar to training): tokens are given, can process all at once (compute-bound)&lt;/p&gt;&#xA;&lt;p&gt;Decode: need to generate one token at a time (memory-bound)&lt;/p&gt;&#xA;&lt;h2 id=&#34;fast-inference&#34;&gt;&#xA;  Fast inference&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#fast-inference&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;systems-optimization&#34;&gt;&#xA;  Systems optimization&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#systems-optimization&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;KV caching&lt;/p&gt;&#xA;&lt;p&gt;Batching&lt;/p&gt;&#xA;&lt;h2 id=&#34;cheaper-models&#34;&gt;&#xA;  CHeaper models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#cheaper-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;model pruning&lt;/p&gt;&#xA;&lt;p&gt;quantization&lt;/p&gt;&#xA;&lt;p&gt;distillation&lt;/p&gt;&#xA;&lt;p&gt;Speculative decoding: use a cheaper &amp;ldquo;draft&amp;rdquo; model to generate multiple tokens, then use the full model to score in parallel (exact decoding).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Frontier models</title>
      <link>http://localhost:1313/docs/transformers/models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/models/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table&#34;&gt;https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;closed-models&#34;&gt;&#xA;  Closed models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#closed-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;API access only&lt;/p&gt;&#xA;&lt;h2 id=&#34;open-weight-models&#34;&gt;&#xA;  Open-weight models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#open-weight-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;weights available&lt;/p&gt;&#xA;&lt;h2 id=&#34;open-source-models&#34;&gt;&#xA;  Open-source models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#open-source-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;weights, data, training details available&lt;/p&gt;&#xA;&lt;h2 id=&#34;bert&#34;&gt;&#xA;  BERT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#bert&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;year&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;architecture&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;type&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;open&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;# parameters&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;who&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;checkpoint&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;tokenizer&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;2018 Oct&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/bert&#34;&gt;&lt;code&gt;BERT&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;✅&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;340M&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Google&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;WordPiece&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/albert&#34;&gt;&lt;code&gt;ALBERT&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/electra&#34;&gt;&lt;code&gt;ELECTRA&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/roberta&#34;&gt;&lt;code&gt;RoBERTa&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;2019 Oct&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/model_doc/distilbert&#34;&gt;&lt;code&gt;DistilBERT&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;✅&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;66 M&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;HuggingFace&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;2019 Oct&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;BART&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder-decoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;400M&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Meta&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;2019 Oct&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;code&gt;T5&lt;/code&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;encoder-decoder&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;11B&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Google&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;SentencePiece&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;gpt&#34;&gt;&#xA;  GPT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gpt&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Open AI, closed, decoder&lt;/p&gt;</description>
    </item>
    <item>
      <title>MoE</title>
      <link>http://localhost:1313/docs/transformers/moe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/moe/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1701.06538&#34;&gt;https://arxiv.org/pdf/1701.06538&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling</title>
      <link>http://localhost:1313/docs/transformers/scaling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/scaling/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Use data from experiments at small scale to predict hyperparameters/loss at large scale.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;scaling-laws&#34;&gt;&#xA;  Scaling laws&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#scaling-laws&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Given a FLOPs budget (&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \(C\)&#xA;&lt;/span&gt;&#xA;), use a bigger model (&lt;span&gt;&#xA;  \(N\)&#xA;&lt;/span&gt;&#xA;) or train on more tokens (&lt;span&gt;&#xA;  \(D\)&#xA;&lt;/span&gt;&#xA;)?&lt;/p&gt;&#xA;&lt;span&gt;&#xA;  \[D^* = 20 \times N^*\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2001.08361&#34;&gt;https://arxiv.org/pdf/2001.08361&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2203.15556&#34;&gt;https://arxiv.org/pdf/2203.15556&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>SSM</title>
      <link>http://localhost:1313/docs/transformers/ssm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/ssm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.10866&#34;&gt;https://arxiv.org/abs/2302.10866&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Datasets</title>
      <link>http://localhost:1313/docs/transformers/datasets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/transformers/datasets/</guid>
      <description>&lt;p&gt;Pile - &lt;a href=&#34;https://arxiv.org/pdf/2101.00027&#34;&gt;https://arxiv.org/pdf/2101.00027&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
