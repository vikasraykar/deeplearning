<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Deep Learning</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Models</title>
      <link>http://localhost:1313/docs/training/model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/model/</guid>
      <description>&lt;h2 id=&#34;models&#34;&gt;&#xA;  Models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Linear Regression&lt;/p&gt;&#xA;&lt;p&gt;Logistic Regression&lt;/p&gt;&#xA;&lt;p&gt;MLP&lt;/p&gt;&#xA;&lt;h2 id=&#34;parameters&#34;&gt;&#xA;  Parameters&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#parameters&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;loss-functions&#34;&gt;&#xA;  Loss functions&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#loss-functions&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Gradient Descent</title>
      <link>http://localhost:1313/docs/training/gradient_descent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/gradient_descent/</guid>
      <description>&lt;h2 id=&#34;gradient-descent&#34;&gt;&#xA;  Gradient Descent&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gradient-descent&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Steepest descent.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Let &lt;span&gt;&#xA;  \(\mathbf{w}\)&#xA;&lt;/span&gt;&#xA; be a vector of all the parameters for a model.&lt;/p&gt;&#xA;&lt;p&gt;Let &lt;span&gt;&#xA;  \(L(\mathbf{w})\)&#xA;&lt;/span&gt;&#xA; be the loss function (or error function).&lt;/p&gt;&#xA;&lt;p&gt;We need to choose the model parameters that optimizes (minimizes) the loss function.&lt;/p&gt;&#xA;&lt;span&gt;&#xA;  \[&#xA;\hat{\mathbf{w}} = \argmin_{\mathbf{w}} L(\mathbf{w})&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;p&gt;Let &lt;span&gt;&#xA;  \(\nabla L(\mathbf{w})\)&#xA;&lt;/span&gt;&#xA; be the &lt;strong&gt;gradient vector&lt;/strong&gt;, where each element is the partial derivative of the loss fucntion wrt each parameter.&lt;/p&gt;&#xA;&lt;p&gt;The gradient vector points in the direction of the greatest rate of increase of the loss function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Backpropagation</title>
      <link>http://localhost:1313/docs/training/backpropagation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/backpropagation/</guid>
      <description>&lt;h2 id=&#34;backpropagation&#34;&gt;&#xA;  Backpropagation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#backpropagation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;algorithmic-differenciation&#34;&gt;&#xA;  Algorithmic differenciation&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#algorithmic-differenciation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;autograd&#34;&gt;&#xA;  Autograd&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#autograd&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Normalization</title>
      <link>http://localhost:1313/docs/training/normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/normalization/</guid>
      <description>&lt;h2 id=&#34;batch-normalization&#34;&gt;&#xA;  Batch normalization&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#batch-normalization&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;img src=&#34;http://localhost:1313/batch.jpeg&#34; alt=&#34;Batch normalization&#34; width=&#34;400&#34;/&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/batch.jpeg&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;In batch normalization the mean and variance are computed across the mini-batch separately for each feature/hidden unit. For a mini-batch of size B&#xA;&#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \[&#xA;\mu_i = \frac{1}{B} \sum_{n=1}^{B} a_{ni}&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;span&gt;&#xA;  \[&#xA;\sigma_i^2 = \frac{1}{B} \sum_{n=1}^{B} (a_{ni}-\mu_i)^2&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;We normalize the pre-activations as follows.&#xA;&lt;span&gt;&#xA;  \[&#xA;\hat{a}_{ni} = \frac{a_{ni}-\mu_i}{\sqrt{\sigma_i^2+\delta}}&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;span&gt;&#xA;  \[&#xA;\tilde{a}_{ni} = \gamma_i \hat{a}_{ni} + \beta_i&#xA;\]&#xA;&lt;/span&gt;&#xA;&lt;/p&gt;&#xA;&lt;a  href=&#34;https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;PyTorch&lt;/a&gt;&#xA;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;m&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;nn&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;BatchNorm1d&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;num_features&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;layer-normalization&#34;&gt;&#xA;  Layer normalization&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-normalization&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;img src=&#34;http://localhost:1313/layer.jpeg&#34; alt=&#34;Layer normalization&#34; width=&#34;300&#34;/&gt;&#xA;&lt;p&gt;In layer normalization the mean and variance are computed across the feature/hidden unit for each example seprately.&#xA;&lt;span&gt;&#xA;  \[&#xA;\mu_n = \frac{1}{M} \sum_{i=1}^{M} a_{ni}&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;span&gt;&#xA;  \[&#xA;\sigma_n^2 = \frac{1}{M} \sum_{i=1}^{M} (a_{ni}-\mu_i)^2&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;We normalize the pre-activations as follows.&#xA;&lt;span&gt;&#xA;  \[&#xA;\hat{a}_{ni} = \frac{a_{ni}-\mu_n}{\sqrt{\sigma_n^2+\delta}}&#xA;\]&#xA;&lt;/span&gt;&#xA;&#xA;&lt;span&gt;&#xA;  \[&#xA;\tilde{a}_{ni} = \gamma_n \hat{a}_{ni} + \beta_n&#xA;\]&#xA;&lt;/span&gt;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Regularization</title>
      <link>http://localhost:1313/docs/training/regularization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/regularization/</guid>
      <description>&lt;p&gt;Dropout&lt;/p&gt;&#xA;&lt;p&gt;Early stopping&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training loop</title>
      <link>http://localhost:1313/docs/training/training_loop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/training_loop/</guid>
      <description>&lt;h2 id=&#34;training-loop&#34;&gt;&#xA;  Training loop&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#training-loop&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch.optim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;SGD&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch.optim.lr_scheduler&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;ExponentialLR&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;SGD&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;parameters&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(),&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;lr&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;momentum&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;scheduler&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;ExponentialLR&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;optimizer&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;gamma&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00a8c8&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;epoch&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;range&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;n_epochs&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#00a8c8&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;target&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;dataset&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;optimizer&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;zero_grad&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;loss_fn&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;loss&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;backward&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;optimizer&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;step&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#111&#34;&gt;scheduler&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;step&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Quiz</title>
      <link>http://localhost:1313/docs/training/quiz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/quiz/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;What is the most widely used optimizer ? What are the typically used parameters of the optimizer ?&lt;/li&gt;&#xA;&lt;li&gt;For SGD with momemtum show that it increases the effective learning rate from &lt;span&gt;&#xA;  \(\eta\)&#xA;&lt;/span&gt;&#xA; to &lt;span&gt;&#xA;  \(\frac{\eta}{(1-\mu)}\)&#xA;&lt;/span&gt;&#xA;.&lt;/li&gt;&#xA;&lt;li&gt;In Attention Is All You Need paper what is the optimizer and the learning rate scheduler used.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Coding</title>
      <link>http://localhost:1313/docs/training/coding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/training/coding/</guid>
      <description>&lt;h2 id=&#34;coding-assignment&#34;&gt;&#xA;  Coding assignment&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#coding-assignment&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Plot learning curve for 3 differnt optimizers.&lt;/p&gt;&#xA;&lt;p&gt;numpy&lt;/p&gt;&#xA;&lt;p&gt;pytorch&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/docs/shortcodes/columns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/shortcodes/columns/</guid>
      <description>&lt;h1 id=&#34;columns&#34;&gt;&#xA;  Columns&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#columns&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Columns help organize shorter pieces of content horizontally for readability.&lt;/p&gt;&#xA;&lt;h2 id=&#34;example&#34;&gt;&#xA;  Example&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{{% columns [ratio=&amp;#34;1:1&amp;#34;] [class=&amp;#34;...&amp;#34;] %}} &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!-- begin columns block --&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Left Content&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Lorem markdownum insigne...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!-- magic separator, between columns --&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Mid Content&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Lorem markdownum insigne...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;---&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!-- magic separator, between columns --&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# Right Content&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Lorem markdownum insigne...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{{% /columns %}}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;book-columns flex flex-wrap&#34;&gt;&#xA;&lt;div class=&#34;flex-even markdown-inner&#34; style=&#34;flex-grow: 1;&#34;&gt;&#xA;&lt;h3 id=&#34;left-content&#34;&gt;&#xA;  Left Content&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#left-content&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat&#xA;stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa&#xA;protulit, sed sed aere valvis inhaesuro Pallas animam: qui &lt;em&gt;quid&lt;/em&gt;, ignes.&#xA;Miseratus fonte Ditis conubia.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/docs/shortcodes/mermaid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/shortcodes/mermaid/</guid>
      <description>&lt;h1 id=&#34;mermaid-chart&#34;&gt;&#xA;  Mermaid Chart&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mermaid-chart&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mermaid-js.github.io/&#34;&gt;MermaidJS&lt;/a&gt; is library for generating svg charts and diagrams from text.&lt;/p&gt;&#xA;&lt;blockquote class=&#34;book-hint info&#34;&gt;&#xA;&lt;p&gt;&lt;strong&gt;Override Mermaid initialization config&lt;/strong&gt;&lt;br&gt;&#xA;To override the &lt;a href=&#34;https://mermaid-js.github.io/mermaid/#/Setup&#34;&gt;initialization config&lt;/a&gt; for Mermaid,&#xA;create a &lt;code&gt;mermaid.json&lt;/code&gt; file in your &lt;code&gt;assets&lt;/code&gt; folder!&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;example&#34;&gt;&#xA;  Example&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#example&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;book-columns flex flex-wrap&#34;&gt;&#xA;&lt;div class=&#34;flex-even markdown-inner&#34; style=&#34;flex-grow: 1;&#34;&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-tpl&#34; data-lang=&#34;tpl&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;{{&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#75af00&#34;&gt;mermaid&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#75af00&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;...&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;}}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stateDiagram-v2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    State1: The state with a note&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    note right of State1&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        Important information! You can write&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        notes.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    end note&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    State1 --&amp;gt; State2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    note left of State2 : This is the note to the left.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;{{&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#75af00&#34;&gt;mermaid&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;}}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;&#xA;&lt;div class=&#34;flex-even markdown-inner&#34; style=&#34;flex-grow: 1;&#34;&gt;&#xA;&lt;pre class=&#34;mermaid&#34;&gt;&#xA;stateDiagram-v2&#xA;    State1: The state with a note&#xA;    note right of State1&#xA;        Important information! You can write&#xA;        notes.&#xA;    end note&#xA;    State1 --&gt; State2&#xA;    note left of State2 : This is the note to the left.&#xA;&lt;/pre&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/docs/shortcodes/section/first-page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/shortcodes/section/first-page/</guid>
      <description>&lt;h1 id=&#34;first-page&#34;&gt;&#xA;  First page&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#first-page&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/docs/shortcodes/section/second-page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/shortcodes/section/second-page/</guid>
      <description>&lt;h1 id=&#34;second-page&#34;&gt;&#xA;  Second Page&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#second-page&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
