---
title: Quiz
weight: 8
bookToc: true
---

- What is the most widely used optimizer ? What are the typically used parameters of the optimizer ?
- For SGD with momemtum show that it increases the effective learning rate from {{< katex >}}\eta{{< /katex >}} to {{< katex >}}\frac{\eta}{(1-\mu)}{{< /katex >}}.
- In Attention Is All You Need paper what is the optimizer and the learning rate scheduler used.
