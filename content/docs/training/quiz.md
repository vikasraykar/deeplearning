---
title: Quiz
weight: 7
bookToc: true
---

## Quiz

{{< katex >}}{{< /katex >}}

> Derive the gradient of the loss function for linear regression and logistic regression.

> Plot binary entropy.

> WHy don't you use MSE loss for binary classification ?

> What is the most widely used optimizer ? What are the typically used parameters of the optimizer ?

> For SGD with momemtum show that it increases the effective learning rate from {{< katex >}}\eta{{< /katex >}} to {{< katex >}}\frac{\eta}{(1-\mu)}{{< /katex >}}.

> In [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper what is the optimizer and the learning rate scheduler used ?

> What is the disadvantage of forward-mode automatic differentiation ?

> What is the difference between batch and layer normalization ?
